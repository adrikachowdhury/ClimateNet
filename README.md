# ğŸŒ ClimateNet: A Multi-Faceted Classifier for Analyzing Climate Change Discourse

**Authors:** <sup>$</sup>Tustee Mazumdar, <sup>$</sup>Adrika Chowdhury, Abu Nowshed Chy, and Tarem Ahmed || $- Equal Contribution ||

---

## ğŸ›ï¸ Publication Status

This paper, *â€œClimateNet: A Multi-Faceted Classifier for Analyzing Climate Change Discourse,â€* has been **accepted and presented at the IEEE Region 10 Humanitarian Technology Conference (R10-HTC 2025)**.  
It is currently **in press and will be published soon in the IEEE Xplore digital library**.

---

## ğŸ§© Overview

**ClimateNet** is a **multi-task text classification framework** designed to analyze the multifaceted discourse surrounding **climate change on social media**. It leverages **transformer-based contextual embeddings (BERT, RoBERTa, DistilBERT, ClimateBERT)** integrated with a **Bidirectional LSTM (BiLSTM)** and a **Multilayer Perceptron (MLP)** classifier to capture both semantic and sequential dependencies in textual data.  

The model aims to uncover diverse perspectivesâ€”including stance, relevance, humor, and hateâ€”within climate-related conversations, aligning with **UN Sustainable Development Goal (SDG) 13: Climate Action**.

---

## ğŸ§  Research Motivation

Online discussions on climate change reflect a range of public opinionsâ€”from support and opposition to humor and hostility. Understanding these nuances helps policymakers, researchers, and organizations promote informed awareness and counter harmful narratives.  

However, analyzing such short, noisy, and imbalanced microblog data (e.g., tweets) is challenging. ClimateNet addresses these issues through:
- **Contextualized embeddings** from transformers  
- **Sequential learning** via BiLSTM  
- **Class imbalance handling** using weighted cross-entropy and oversampling  
- **Multi-aspect classification** across six tasks  

---

## âš™ï¸ Architecture

The proposed **ClimateNet** framework follows a **hybrid multi-model architecture** that combines transformer-based feature extraction with sequential and dense learning modules for robust text classification.

Each transformer (BERT, RoBERTa, DistilBERT, ClimateBERT) is fine-tuned and followed by a BiLSTM and MLP classifier.  

- **Transformers:** Extract deep contextual features
- **BiLSTM:** Captures long- and short-term dependencies
- **MLP:** Maps learned representations to output labels


### ğŸ§  Pipeline Components

1. **Data Formatting:**  
   Raw social media texts and their associated labels are preprocessed and tokenized into a structured input format suitable for transformer models.

2. **Feature Extraction (BERT, RoBERTa, DistilBERT, ClimateBERT):**  
   Each transformer independently extracts deep contextual embeddings from the formatted text.  
   These embeddings capture the semantic nuances and contextual relationships in climate-related discourse.

3. **Sequential Learning (BiLSTM):**  
   The extracted features are passed through a **Bidirectional LSTM**, which models long-term dependencies by processing sequences in both forward and backward directions.  
   This step enhances temporal understanding and context retention.

4. **Classification Module (MLP):**  
   The BiLSTM outputs are fed into a **Multilayer Perceptron (MLP)** classifier, which produces the final predictions for each task.  
   Depending on the classification objective (binary or multiclass), a sigmoid or softmax activation is applied.

---

In essence, ClimateNet integrates **contextual transformers** with **temporal sequence modeling** and **dense classification layers**, enabling the framework to accurately predict multi-faceted aspects of climate change discourse across six tasks.

---

## ğŸ“š Tasks

ClimateNet performs **six independent NLP classification tasks** on the *ClimaConvo* dataset:

| Task | Description | Label Type |
|------|--------------|-------------|
| **Relevance Detection** | Classify whether a tweet is related to climate change | Binary (0â€“Non-relevant, 1â€“Relevant) |
| **Stance Detection** | Identify stance: Support, Oppose, or Neutral | Multiclass (0â€“Support, 1â€“Oppose, 2â€“Neutral) |
| **Hate Speech Detection** | Detect presence of hate content | Binary (0â€“Non-hate, 1â€“Hate) |
| **Direction of Hate Speech** | Determine if hate is direct or indirect | Binary (0â€“Undirected, 1â€“Directed) |
| **Target of Hate Speech** | Identify if hate targets individuals, organizations, or communities | Multiclass (0â€“Individual, 1â€“Organization, 2â€“Community) |
| **Humor Detection** | Detect humorous or sarcastic tone | Binary (0â€“Non-humor, 1â€“Humor) |

---

## ğŸ§¾ Dataset

We used **ClimaConvo**,  a publicly available dataset comprising **15,309 English climate-related tweets**, annotated across the six dimensions listed above.  
Data split: **80% train / 20% test** (stratified).  
Main evaluation metric: **Macro-averaged F1-score**.

---

## ğŸ“‚ Repository Structure

```bash
Notebooks/
â”œâ”€â”€ Relevance/
â”‚   â”œâ”€â”€ BERT_Relevance.ipynb
â”‚   â”œâ”€â”€ ClimateBERT_Relevance.py
â”‚   â”œâ”€â”€ DistilBERT_Relevance.py
â”‚   â””â”€â”€ RoBERTa_Relevance.py
â”‚
â”œâ”€â”€ Stance/
â”‚   â”œâ”€â”€ BERT_Stance.ipynb
â”‚   â”œâ”€â”€ ClimateBERT_Stance.ipynb
â”‚   â”œâ”€â”€ DistilBERT_Stance.ipynb
â”‚   â””â”€â”€ RoBERTa_Stance.ipynb
â”‚
â”œâ”€â”€ Hate_Speech/
â”‚   â”œâ”€â”€ BERT_HateSpeech.ipynb
â”‚   â”œâ”€â”€ ClimateBERT_HateSpeech.ipynb
â”‚   â”œâ”€â”€ DistilBERT_HateSpeech.ipynb
â”‚   â””â”€â”€ RoBERTa_HateSpeech.ipynb
â”‚
â”œâ”€â”€ Hate_Speech_Directions/
â”‚   â”œâ”€â”€ BERT_Directions.ipynb
â”‚   â”œâ”€â”€ ClimateBERT_Directions.ipynb
â”‚   â”œâ”€â”€ DistilBERT_Directions.ipynb
â”‚   â””â”€â”€ RoBERTa_Directions.ipynb
â”‚
â”œâ”€â”€ Hate_Speech_Targets/
â”‚   â”œâ”€â”€ BERT_Targets.ipynb
â”‚   â”œâ”€â”€ ClimateBERT_Targets.ipynb
â”‚   â”œâ”€â”€ DistilBERT_Targets.ipynb
â”‚   â””â”€â”€ RoBERTa_Targets.ipynb
â”‚
â””â”€â”€ Humor/
    â”œâ”€â”€ BERT_Humor.ipynb
    â”œâ”€â”€ ClimateBERT_Humor.ipynb
    â”œâ”€â”€ DistilBERT_Humor.ipynb
    â””â”€â”€ RoBERTa_Humor.ipynb
```
---

Inside the `Notebooks` directory, each subdirectories correspond to a **specific classification task**, and within each folder, four transformer-based implementations are provided separately for modularity and reproducibility.
All scripts include:
- Dataset preprocessing and tokenization  
- Model fine-tuning and BiLSTM integration  
- Training, evaluation, and result saving  

---

## ğŸ’» Installation

To replicate our experiments or explore the ClimateNet notebooks locally, please follow these steps:

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/<your-username>/ClimateNet.git
cd ClimateNet
```

### 2ï¸âƒ£ Set Up the Python Environment
Use Python 3.10+

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run the Notebooks

Upload the notebook of your choice (e.g., ```Notebooks/Stance/DistilBERT_Stance.ipynb```) to Colab and ensure the runtime is set to GPU for faster training.


## ğŸ™ Acknowledgment

This research builds upon the **ClimaConvo** dataset introduced by **Shiwakoti et al. (2024)** in their paper *â€œAnalyzing the Dynamics of Climate Change Discourse on Twitter: A New Annotated Corpus and Multi-Aspect Classificationâ€* (LREC-COLING 2024).  
We gratefully acknowledge their contribution for providing the annotated benchmark dataset that enabled our experiments and evaluation.
